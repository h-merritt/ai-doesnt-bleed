{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5633e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, sys, math, re\n",
    "from IPython.display import display, clear_output, Markdown, Latex\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from operator import concat\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f11457",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to nicely display numeric word scores\n",
    "\n",
    "def show(sorted_words, n=20):\n",
    "    markdown_table = \"|Score | Word|\\n|---:|:---|\\n\"\n",
    "    for score, word in sorted_words[:n]:\n",
    "        markdown_table += \"|{:.3f}|{}|\\n\".format(score, word)\n",
    "    display(Markdown(markdown_table))\n",
    "    \n",
    "def show_counter(counter, n=20):\n",
    "    markdown_table = \"|Count | Word|\\n|---:|:---|\\n\"\n",
    "    for word, score in counter.most_common(n):\n",
    "        markdown_table += \"|{}|{}|\\n\".format(score, word)\n",
    "    display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800ab019",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"tv_combined_clean.txt\" # this is human youth collapsed across gender\n",
    "\n",
    "sentences = []\n",
    "all_counter = Counter()\n",
    "word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")\n",
    "\n",
    "with open(text_file, encoding=\"utf-8\") as reader:\n",
    "    for line in reader:\n",
    "        line = line.strip()\n",
    "        tokens = word_pattern.findall(line)\n",
    "        all_counter.update(tokens)\n",
    "        \n",
    "        sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478c4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a22a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_in_context(query):\n",
    "    table_markdown = \"|left context|word|right context|\\n|--:|--|:--|\\n\"\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        if not query in sentence:\n",
    "            continue\n",
    "            \n",
    "        for i, word in enumerate(sentence):\n",
    "            if word == query:\n",
    "                start = max(i-window_size, 0)\n",
    "                left_context = sentence[start:i]\n",
    "                right_context = sentence[(i+1):(i+window_size+1)]\n",
    "                table_markdown += \"|{}|{}|{}|\\n\".format(\" \".join(left_context), word, \" \".join(right_context))\n",
    "                    \n",
    "    display(Markdown(table_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f908c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|left context|word|right context|\n",
       "|--:|--|:--|\n",
       "|bosom should resemble the sweet orange of valencia which yearn to be buying a fancy|bra|make you look like these they all have their rib removed and their buttholes i|\n",
       "|is the tell shannon kill yourself if you get how about this i is this|bra|really of course always been i got was it not who insisted from an early|\n",
       "|eleanor roosevelt once one thing every day that scare closed and i think this red|bra|scare both of my we did we got a my you think i just found|\n",
       "|ice but you were eating it figure out why these doodies were so what are|bra|shopping or shark tank is making me i know that rotten kid stole my idea|\n",
       "|thrill and set passion aflame down the depth of your womanly soul own sexy red|bra|sexy red bra red transform you into an object of envy and awe so i|\n",
       "|passion aflame down the depth of your womanly soul own sexy red bra sexy red|bra|red transform you into an object of envy and awe so i have i want|\n",
       "|so i have i want to give it to bonjour to the lovely sexy red|bra|who do you think you one of the it will lift up your my dear|\n",
       "|a red which mean she want u to know or she just like the the|bra|a a say it is a what do we even do with i see what|\n",
       "|horniness by touching her be i know if i wa walking around with a red|bra|on my want somebody to touch my a little i like hanging out with mi|\n",
       "|get i want somebody you have no idea what i you fucknut i guess the|bra|a and jessi is very hi if finished with doubting i thought you might like|\n",
       "|believe we get to sleep next to what if it happens what if under the|bra|this you need to calm but how can i how can it turn miranda san|\n",
       "|cute little i like this a not if you wanna wear cowboy boot and a|bra|full of your you know i can wear whatever i sounds like someone took their|\n",
       "|girl are wearing sexy clothes to protest the dress code important do you want some|bra|to the only reason i have but give them all i use one of them|\n",
       "|to think that like guess i am shut what have i what tastes like the|bra|with several radish in as you can not wearing i get then say you wear|\n",
       "|along at home with our downloadable i went to coding camp last you stuff your|bra|with boys love fuck i even care what these loser my number and number up|\n",
       "|keep pushing it back so in the i have to believe missy understood that the|bra|wa to hold i did not wear the one cup of unstrained ohyeah for my|\n",
       "|disintegrate the moment i get my that place is angels wearing not wearing a fucking|bra|in the cute hate thank what kind of a hate you knew i did not|\n",
       "|know how you me get this you think a bald nerd who wear a radish|bra|know how i wear the drop some salt on this old want to know how|\n",
       "|i get my 447 that place is 448 angels wearing 449 not wearing a fucking|bra|in the 450 cute hate thank 451 what kind of 452 39 a hate you|\n",
       "|time in japan teaching english in my rebecca is alex looking at robert julie here|bra|how about hold hitting brandt in the get away from my brian probably look at|\n",
       "|tell you it mean girl in so and they said they know why wearing a|bra|ana because nothing to go in so yeah really thanks for telling me becca your|\n",
       "|bosom should resemble the sweet orange of valencia which yearn to be buying a fancy|bra|make you look like these they all have their rib removed and their buttholes i|\n",
       "|is the tell shannon kill yourself if you get how about this i is this|bra|really of course always been i got was it not who insisted from an early|\n",
       "|eleanor roosevelt once one thing every day that scare closed and i think this red|bra|scare both of my we did we got a my you think i just found|\n",
       "|ice but you were eating it figure out why these doodies were so what are|bra|shopping or shark tank is making me i know that rotten kid stole my idea|\n",
       "|thrill and set passion aflame down the depth of your womanly soul own sexy red|bra|sexy red bra red transform you into an object of envy and awe so i|\n",
       "|passion aflame down the depth of your womanly soul own sexy red bra sexy red|bra|red transform you into an object of envy and awe so i have i want|\n",
       "|so i have i want to give it to bonjour to the lovely sexy red|bra|who do you think you one of the it will lift up your my dear|\n",
       "|a red which mean she want u to know or she just like the the|bra|a a say it is a what do we even do with i see what|\n",
       "|horniness by touching her be i know if i wa walking around with a red|bra|on my want somebody to touch my a little i like hanging out with mi|\n",
       "|get i want somebody you have no idea what i you fucknut i guess the|bra|a and jessi is very hi if finished with doubting i thought you might like|\n",
       "|believe we get to sleep next to what if it happens what if under the|bra|this you need to calm but how can i how can it turn miranda san|\n",
       "|cute little i like this a not if you wanna wear cowboy boot and a|bra|full of your you know i can wear whatever i sounds like someone took their|\n",
       "|girl are wearing sexy clothes to protest the dress code important do you want some|bra|to the only reason i have but give them all i use one of them|\n",
       "|to think that like guess i am shut what have i what tastes like the|bra|with several radish in as you can not wearing i get then say you wear|\n",
       "|along at home with our downloadable i went to coding camp last you stuff your|bra|with boys love fuck i even care what these loser my number and number up|\n",
       "|keep pushing it back so in the i have to believe missy understood that the|bra|wa to hold i did not wear the one cup of unstrained ohyeah for my|\n",
       "|disintegrate the moment i get my that place is angels wearing not wearing a fucking|bra|in the cute hate thank what kind of a hate you knew i did not|\n",
       "|know how you me get this you think a bald nerd who wear a radish|bra|know how i wear the drop some salt on this old want to know how|\n",
       "|i get my 447 that place is 448 angels wearing 449 not wearing a fucking|bra|in the 450 cute hate thank 451 what kind of 452 39 a hate you|\n",
       "|time in japan teaching english in my rebecca is alex looking at robert julie here|bra|how about hold hitting brandt in the get away from my brian probably look at|\n",
       "|tell you it mean girl in so and they said they know why wearing a|bra|ana because nothing to go in so yeah really thanks for telling me becca your|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword_in_context(\"bra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfbadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountWords(text):\n",
    "\n",
    "    previous_context_counters = {} # count words that precede the key\n",
    "    next_context_counters = {} # count words that follow the key\n",
    "\n",
    "    for sentence in text:\n",
    "        for i in range(len(sentence) - 1): # stop at the next-to-last token\n",
    "            word = sentence[i]\n",
    "            next_word = sentence[i+1]\n",
    "        \n",
    "            if not word in next_context_counters:\n",
    "                next_context_counters[word] = Counter()\n",
    "            if not next_word in previous_context_counters:\n",
    "                previous_context_counters[next_word] = Counter()\n",
    "        \n",
    "            next_context_counters[word][next_word] += 1\n",
    "            previous_context_counters[next_word][word] += 1\n",
    "            \n",
    "    return previous_context_counters, next_context_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463aa6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_context_counters,next_context_counters = CountWords(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85f0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetContextCounters(text):\n",
    "    \n",
    "    word_context_counters = {}\n",
    "\n",
    "    for sentence in text:\n",
    "        \n",
    "        for i, word in enumerate(sentence):\n",
    "            start = max(i-window_size, 0)\n",
    "            left_context = sentence[start:i]\n",
    "            right_context = sentence[(i+1):(i+window_size+1)]\n",
    "        \n",
    "            if not word in word_context_counters:\n",
    "                word_context_counters[word] = Counter()\n",
    "        \n",
    "            word_context_counters[word].update(left_context)\n",
    "            word_context_counters[word].update(right_context)\n",
    "    return word_context_counters\n",
    "\n",
    "word_context_counters = GetContextCounters(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3a6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_ratio(word,context):\n",
    "    counter = context[word]\n",
    "    \n",
    "    all_sum = sum(all_counter.values()) ## N\n",
    "    word_sum = sum(counter.values())    ## N(w)\n",
    "    \n",
    "    comparisons = []\n",
    "    for c in counter.keys():\n",
    "        score = counter[c] * math.log((counter[c] * all_sum) / (word_sum * all_counter[c]))\n",
    "        comparisons.append((score, c))\n",
    "    \n",
    "    return sorted(comparisons, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d28eea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|Score | Word|\n",
       "|---:|:---|\n",
       "|32.944|got|\n",
       "|27.213|not|\n",
       "|23.322|expelled|\n",
       "|23.029|sounds|\n",
       "|21.964|i|\n",
       "|21.235|it|\n",
       "|20.781|pussy|\n",
       "|17.690|a|\n",
       "|14.143|get|\n",
       "|13.896|but|\n",
       "|13.885|smell|\n",
       "|13.241|then|\n",
       "|12.626|gross|\n",
       "|11.856|of|\n",
       "|11.730|what|\n",
       "|11.661|skittle|\n",
       "|11.661|sixth|\n",
       "|11.661|rite|\n",
       "|11.661|ovum|\n",
       "|11.661|minions|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(log_ratio(\"period\",word_context_counters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bfa66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"period\",\"bra\",\"voice\",\"hair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91527e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save top words of each keyword and their log ratios to later compare to shuffled log ratios\n",
    "\n",
    "ntop = 20 # how many of the top words do we want to compare\n",
    "# create empty arrays\n",
    "top_words = [[0] * len(keywords) for i in range(ntop)]\n",
    "top_logs = np.zeros((len(keywords),ntop))\n",
    "\n",
    "for word in range(len(keywords)):\n",
    "    for n in range(ntop):\n",
    "        top_words[n][word] = log_ratio(keywords[word],word_context_counters)[n][1]\n",
    "        top_logs[word,n] = log_ratio(keywords[word],word_context_counters)[n][0] \n",
    "        \n",
    "top_words = np.transpose(np.array(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f57c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "# shuffle text and calculated shuffled log ratios\n",
    "niter = 10000 #10000\n",
    "max_split = 103 # this is average length of journal entries\n",
    "flatlist = reduce(concat, sentences)\n",
    "\n",
    "lrs_shuf = np.zeros((ntop,len(keywords),niter))\n",
    "#top_words=list(top_words)\n",
    "top = np.unique(np.concatenate(top_words))\n",
    "\n",
    "for i in range(niter):\n",
    "    if i in np.arange(10) * 1000:\n",
    "        print(i)\n",
    "        \n",
    "    # shuffle\n",
    "    shuf = random.sample(flatlist,k=len(flatlist))\n",
    "    # return to nested list type since above code assumes that format\n",
    "    shuf_sep = [shuf[i:i + max_split ] for i in range(0, len(shuf), max_split )]\n",
    "    \n",
    "    # get word context counters for shuffled corpus\n",
    "    context_shuf = GetContextCounters(shuf_sep)\n",
    "    \n",
    "    # get log ratios for key words in shuffled corpus\n",
    "    key_ind = 0\n",
    "    for keyword in range(len(keywords)):\n",
    "        log_ratios = log_ratio(keywords[keyword],context_shuf)\n",
    "        \n",
    "        # get indices of words that have high pmi with keywords\n",
    "        ws = []\n",
    "        [ws.append(log_ratios[x][1]) for x in range(len(log_ratios))]\n",
    "    \n",
    "        # need to match words with top unshuffled lr to their shuffled lr\n",
    "\n",
    "        top_ind = 0\n",
    "        for topword in top_words[keyword]:\n",
    "            if topword in ws:\n",
    "                #lr = log_ratios[ws.index(topword)][0]\n",
    "                lrs_shuf[top_ind,key_ind,i] = log_ratios[ws.index(topword)][0]\n",
    "\n",
    "            top_ind += 1\n",
    "\n",
    "        key_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8100e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate p-values of observed log ratios given shuffled log ratios\n",
    "ps = np.zeros((ntop,len(keywords)))\n",
    "\n",
    "for topword in range(ntop):\n",
    "    \n",
    "    for keyword in range(len(keywords)):\n",
    "        \n",
    "         ps[topword,keyword] = sum(lrs_shuf[topword,keyword,:] > top_logs[keyword,topword])/niter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "996aa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   KeyWords MatchWords   LogRatios  pValues\n",
      "0    period        got   32.944327   0.0000\n",
      "1    period        red   87.910155   0.0000\n",
      "2    period       tall   25.540196   0.0000\n",
      "3    period       hair  134.528352   0.0000\n",
      "4    period        not   27.212861   0.0000\n",
      "..      ...        ...         ...      ...\n",
      "75     hair       lace   20.455658   0.0000\n",
      "76     hair    minions   11.661185   0.0001\n",
      "77     hair        bra   13.916868   0.0013\n",
      "78     hair        mad   10.614124   0.0001\n",
      "79     hair       look   20.397846   0.0003\n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# save log ratios and p-values\n",
    "# cols = keyword, matchword, log_ratio, pval\n",
    "\n",
    "df = pd.DataFrame(np.repeat(keywords,20))\n",
    "df.columns = ['KeyWords']\n",
    "df['MatchWords'] = np.concatenate(np.transpose(top_words))\n",
    "df['LogRatios'] = np.concatenate(np.transpose(top_logs))\n",
    "df['pValues'] = np.concatenate(ps)\n",
    "\n",
    "print(df)\n",
    "df.to_csv('pmi_tv_10000shuf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092edfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
